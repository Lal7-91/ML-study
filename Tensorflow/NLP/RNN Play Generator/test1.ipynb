{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### source code: https://colab.research.google.com/drive/1ysEKrw_LE2jMndo1snrZUh5w87LQsCxk#forceEdit=true&sandboxMode=true&scrollTo=CRGOx6_v4eZ_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files      # to upload file in google colab env\n",
    "# path_to_file = list(files.upload().keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "  return np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: First Citizen\n",
      "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "# lets look at how part of our text is encoded\n",
    "print(\"Text:\", text[:13])\n",
    "print(\"Encoded:\", text_to_int(text[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "  try:\n",
    "    ints = ints.numpy()\n",
    "  except:\n",
    "    pass\n",
    "  return ''.join(idx2char[ints])\n",
    "\n",
    "print(int_to_text(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100  # length of sequence for a training example\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):  # for the example: hello\n",
    "    input_text = chunk[:-1]  # hell\n",
    "    target_text = chunk[1:]  # ello\n",
    "    return input_text, target_text  # hell, ello\n",
    "\n",
    "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "\n",
      "OUTPUT\n",
      "irst Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you \n",
      "\n",
      "OUTPUT\n",
      "re all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you k\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(2):\n",
    "  print(\"\\n\\nEXAMPLE\\n\")\n",
    "  print(\"INPUT\")\n",
    "  print(int_to_text(x))\n",
    "  print(\"\\nOUTPUT\")\n",
    "  print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           16640     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5330241 (20.33 MB)\n",
      "Trainable params: 5330241 (20.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[ 3.28550814e-03 -3.21296416e-03 -3.94526054e-04 ...  1.78730488e-03\n",
      "   -2.02260958e-03  7.91079458e-03]\n",
      "  [ 4.07655584e-03  4.01577400e-03 -6.31302129e-03 ...  6.36673532e-03\n",
      "    2.60268163e-04  6.78106630e-03]\n",
      "  [ 9.03888512e-03 -2.90617370e-03 -6.54605823e-03 ...  5.64712193e-03\n",
      "   -2.69289571e-03  4.70679067e-03]\n",
      "  ...\n",
      "  [ 1.37190213e-02  9.66157066e-04 -4.80533252e-03 ... -1.36888318e-03\n",
      "    3.67474742e-03  2.63784284e-04]\n",
      "  [ 1.05617484e-02  7.75970565e-03 -4.25249990e-03 ... -3.46542895e-03\n",
      "    1.73613266e-03 -1.88962277e-03]\n",
      "  [ 7.65290158e-03  5.95134450e-03 -7.81845418e-04 ... -6.79687969e-03\n",
      "    2.35800818e-03 -6.29253639e-03]]\n",
      "\n",
      " [[-5.64363872e-05  3.57312406e-03  1.78367272e-03 ...  5.10888174e-03\n",
      "    3.41656269e-03 -8.88154435e-04]\n",
      "  [ 4.78611281e-03  3.35812429e-03  1.23798521e-03 ... -7.61700142e-03\n",
      "    2.03779782e-03 -1.18981604e-03]\n",
      "  [ 3.32397129e-03  3.99772078e-03  3.21600237e-03 ... -9.03803203e-03\n",
      "    2.62341718e-03 -6.06141612e-03]\n",
      "  ...\n",
      "  [-5.59121254e-04  1.23104919e-02  4.24760720e-03 ...  3.31672351e-03\n",
      "    9.81618837e-03  1.11304934e-03]\n",
      "  [-1.08000450e-03  9.86032654e-03  7.04344176e-03 ... -2.56588380e-03\n",
      "    9.49050114e-03 -3.52475955e-03]\n",
      "  [-7.40417466e-03  5.04335202e-03  5.44812623e-03 ... -2.97540613e-03\n",
      "    9.04525258e-03 -4.21968661e-03]]\n",
      "\n",
      " [[-3.04671633e-03  1.00006629e-03  1.77273864e-03 ... -3.87500087e-03\n",
      "    7.28842570e-04 -5.59820968e-04]\n",
      "  [ 5.03218826e-03 -6.27070060e-03 -1.64125429e-03 ... -2.30598217e-03\n",
      "   -2.05123285e-03 -1.60833297e-04]\n",
      "  [ 3.31730023e-03 -2.04767892e-03 -4.90646064e-03 ... -3.74186877e-03\n",
      "    2.01659393e-04 -2.53962679e-03]\n",
      "  ...\n",
      "  [ 7.72907306e-03 -5.35005517e-03 -6.66170754e-03 ... -1.53577491e-03\n",
      "   -7.94714666e-04 -4.03845450e-03]\n",
      "  [ 1.09975785e-02 -5.30952821e-03 -3.24369734e-03 ... -6.24307990e-03\n",
      "    4.05116752e-03 -1.09807905e-02]\n",
      "  [ 1.15346238e-02 -6.63645007e-03 -3.18349223e-03 ... -3.85391130e-03\n",
      "    1.73486618e-03 -1.90889149e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.42979592e-03  1.97796500e-03  2.38032243e-03 ...  1.24528608e-03\n",
      "    3.28585831e-03  3.09836492e-03]\n",
      "  [ 4.26469254e-04 -8.86791851e-04  3.19176237e-03 ... -8.22187983e-04\n",
      "   -1.01630250e-03  4.21756180e-03]\n",
      "  [ 3.37487878e-03  7.40769366e-03  2.75601924e-04 ... -2.40326254e-03\n",
      "    1.93572720e-03  1.62491680e-03]\n",
      "  ...\n",
      "  [ 8.31565633e-03  3.98993958e-03  5.60044660e-04 ... -7.79775251e-03\n",
      "    5.14806667e-03 -6.16348535e-03]\n",
      "  [ 5.76823764e-03  5.14736865e-04 -7.54517736e-03 ... -5.32140490e-03\n",
      "    5.80803491e-03 -4.08564135e-03]\n",
      "  [ 4.98725707e-03  3.62780201e-03 -3.16743343e-03 ... -6.53898111e-04\n",
      "    8.53378139e-03 -3.75106023e-03]]\n",
      "\n",
      " [[ 6.28564553e-03 -6.47422113e-03 -2.47882353e-03 ...  6.99190015e-04\n",
      "   -3.58204031e-03 -2.23678711e-04]\n",
      "  [ 4.48441040e-03 -8.55312217e-03 -6.68739481e-03 ...  7.29320198e-03\n",
      "   -2.25206953e-03 -2.05319840e-03]\n",
      "  [ 5.25941141e-03 -8.49118922e-03 -5.87432506e-03 ...  6.88155461e-03\n",
      "   -3.26279085e-03  6.01142831e-03]\n",
      "  ...\n",
      "  [ 6.26027025e-03 -2.11405195e-03 -3.49612138e-03 ... -6.04293495e-03\n",
      "    3.95266572e-03  1.15953013e-03]\n",
      "  [ 4.41969233e-03  4.79711380e-05  1.02754659e-03 ... -1.00975819e-02\n",
      "    4.83662961e-03 -3.89102730e-03]\n",
      "  [-1.33515825e-03  2.20262376e-03  7.69004226e-04 ... -1.50534995e-02\n",
      "    8.39039031e-03 -3.62897385e-03]]\n",
      "\n",
      " [[-5.64363872e-05  3.57312406e-03  1.78367272e-03 ...  5.10888174e-03\n",
      "    3.41656269e-03 -8.88154435e-04]\n",
      "  [ 5.49850578e-04 -1.07852486e-03 -2.71210936e-03 ...  9.98320431e-03\n",
      "    3.51086841e-03 -2.11902196e-03]\n",
      "  [ 5.79211116e-03 -6.19237963e-03 -4.32987232e-03 ...  7.39548309e-03\n",
      "   -3.47183261e-04 -1.84107141e-03]\n",
      "  ...\n",
      "  [ 7.76003255e-03  7.64918921e-04  4.34659794e-03 ... -1.28510613e-02\n",
      "    1.10376244e-02  1.87091617e-04]\n",
      "  [ 9.55032650e-03  6.79267198e-03 -2.65966868e-03 ... -5.90400957e-03\n",
      "    1.03002694e-02  9.46738815e-04]\n",
      "  [ 8.10973905e-03  1.14147132e-02 -1.78556889e-03 ... -6.90845773e-03\n",
      "    7.17705116e-03 -2.00771098e-03]]], shape=(64, 100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# we can see that the predicition is an array of 64 arrays, one for each entry in the batch\n",
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[ 0.00328551 -0.00321296 -0.00039453 ...  0.0017873  -0.00202261\n",
      "   0.00791079]\n",
      " [ 0.00407656  0.00401577 -0.00631302 ...  0.00636674  0.00026027\n",
      "   0.00678107]\n",
      " [ 0.00903889 -0.00290617 -0.00654606 ...  0.00564712 -0.0026929\n",
      "   0.00470679]\n",
      " ...\n",
      " [ 0.01371902  0.00096616 -0.00480533 ... -0.00136888  0.00367475\n",
      "   0.00026378]\n",
      " [ 0.01056175  0.00775971 -0.0042525  ... -0.00346543  0.00173613\n",
      "  -0.00188962]\n",
      " [ 0.0076529   0.00595134 -0.00078185 ... -0.00679688  0.00235801\n",
      "  -0.00629254]], shape=(100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# lets examine one prediction\n",
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)\n",
    "# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "tf.Tensor(\n",
      "[ 3.2855081e-03 -3.2129642e-03 -3.9452605e-04  8.9770707e-04\n",
      "  4.6463474e-03  6.6446164e-04  4.2595898e-04 -1.2319670e-03\n",
      "  3.9452389e-03  3.1783676e-03 -2.2988691e-04 -7.9560844e-04\n",
      " -3.0262363e-03 -6.0070731e-04 -1.0714831e-03 -1.5464957e-03\n",
      " -1.7502138e-03 -2.3682383e-03  1.5039917e-03  1.3325666e-03\n",
      " -7.5481427e-03 -3.5766896e-03  5.2947900e-04  7.3241475e-03\n",
      "  1.4551028e-05  4.1994629e-03 -7.4335630e-04  1.0522607e-03\n",
      " -2.7264988e-03  9.7377750e-05  3.0652946e-03  1.4019742e-03\n",
      " -1.5395524e-03  2.6159799e-03 -7.6197169e-04  2.7099662e-03\n",
      "  1.5844451e-03  2.3364858e-03 -3.3320258e-03 -8.5290126e-04\n",
      " -3.8816482e-03 -1.7563921e-03 -1.9367144e-04  3.2742070e-03\n",
      " -6.6873961e-04 -1.0884928e-03 -7.7934528e-04 -4.2897416e-03\n",
      " -1.6705997e-04  1.8924256e-03  1.1772482e-03  3.7230311e-03\n",
      " -3.9775576e-03 -5.8540492e-03  2.6282419e-03  5.6976737e-03\n",
      "  1.5590955e-03  5.5066561e-03  2.4569922e-03  7.3113461e-04\n",
      " -6.6230638e-04 -4.5616622e-04  1.7873049e-03 -2.0226096e-03\n",
      "  7.9107946e-03], shape=(65,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# and finally well look at a prediction at the first timestep\n",
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)\n",
    "# and of course its 65 values representing the probabillity of each character occuring next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PEgORQerjUxFw-;HJrzqyUyEghQucSjINj\\nLfJg$'I:GCBCxhqbrovIT\\nHKjLTIVDKOpn,THGaBJj;guS:ttXqsLiGekg&MKNC.;\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars  # and this is what the model predicted for training sequence 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
